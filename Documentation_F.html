<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Documentation technique du modèle d’apprentissage</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 0; background: #f5f5f5; }
    h1 { text-align: center; padding: 20px; color: #333; }
    
    /* Barre de bulles */
    .steps-bar {
      display: flex;
      justify-content: center;
      align-items: center;
      background: #fff;
      padding: 15px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
      position: sticky;
      top: 0;
      z-index: 1000;
      gap: 20px;
      flex-wrap: wrap;
    }
    .step {
      width: 60px;
      height: 60px;
      border-radius: 50%;
      background: #ddd;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: bold;
      cursor: pointer;
      transition: all 0.3s;
    }
    .step.active {
      background: #4CAF50;
      color: #fff;
      transform: scale(1.1);
    }
    .step:hover { background: #66bb6a; color: #fff; }

    /* Sections */
    .content-section {
      display: none;
      background: #fff;
      margin: 20px auto;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 0 6px rgba(0,0,0,0.1);
      width: 90%;
      max-width: 1000px;
      animation: fadeIn 0.5s ease;
    }
    .content-section.active { display: block; }

    /* Images */
    .images { display: flex; justify-content: center; gap: 20px; margin: 20px 0; flex-wrap: wrap; }
    .images img { width: 320px; height: 220px; object-fit: cover; border-radius: 8px; cursor: pointer; box-shadow: 0 0 8px rgba(0,0,0,0.2); }
    .caption { text-align: center; font-style: italic; margin-top: 5px; }

    video { max-width: 100%; border-radius: 8px; box-shadow: 0 0 8px rgba(0,0,0,0.2); }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
  </style>
</head>
<body>

<h1>Documentation technique du modèle d’apprentissage</h1>

<!-- Bulles -->
<div class="steps-bar">
  <div class="step active" onclick="showStep(1)">1</div>
  <div class="step" onclick="showStep(2)">2</div>
  <div class="step" onclick="showStep(3)">3</div>
  <div class="step" onclick="showStep(4)">4</div>
  <div class="step" onclick="showStep(5)">5</div>
  <div class="step" onclick="showStep(6)">6</div>

</div>

<!-- Sections -->
<div id="step1" class="content-section active">
  <h2>1️⃣ Data Collection</h2>
  <p>
    L’étape de <strong>collecte des données brutes</strong> consiste à extraire et centraliser toutes les informations nécessaires à partir des pages produits du magasin <em>Ponera</em> sur Amazon.
  </p>
  
  <h3>🎯 Objectif</h3>
  <p>
    Constituer une base de données fiable, normalisée et exploitable qui servira de fondation à l’entraînement et à l’optimisation du modèle d’intelligence artificielle.
  </p>

  <h3>⚙️ Outil utilisé</h3>
  <p>
    L’extension <strong>IMPORTFROMWEB</strong> pour Google Sheets permet d’automatiser la collecte des données produits. 
    Cette automatisation offre :
  </p>
  <ul>
    <li>Un <strong>gain de temps</strong> dans la récupération des données,</li>
    <li>Une <strong>réduction des erreurs humaines</strong> liées à la saisie manuelle,</li>
    <li>Une <strong>mise à jour dynamique</strong> des informations collectées.</li>
  </ul>

  <h3>📦 Données collectées</h3>
  <p>Les caractéristiques extraites incluent :</p>
  <ul>
    <li><strong>ASIN</strong> : identifiant unique du produit sur Amazon,</li>
    <li><strong>Titre du produit</strong>,</li>
    <li><strong>Prix</strong>,</li>
    <li><strong>Note moyenne des clients</strong>,</li>
    <li><strong>Nombre total de commentaires</strong>,</li>
    <li><strong>Contenu des avis clients</strong>.</li>
  </ul>

  <h3>✅ Résultat attendu</h3>
  <p>
    Une base de données organisée dans Google Sheets, rassemblant toutes les informations nécessaires sous un format uniforme, prête à être utilisée pour les analyses et les applications d’IA.
  </p>

  <video controls>
    <source src="data_collection.mp4" type="video/mp4">
    Votre navigateur ne supporte pas la lecture vidéo.
  </video>
</div>

<div id="step2" class="content-section">
    <h2>2️⃣ Nettoyage des textes</h2>
    
    <p>
      Cette étape consiste à <strong>préparer et uniformiser la base de données textuelles</strong> afin de garantir la qualité des informations qui seront utilisées dans les traitements d’analyse et dans l’entraînement du modèle d’intelligence artificielle.  
      Un texte brut contient souvent du bruit (ponctuation, majuscules, mots sans importance, etc.), ce qui peut fausser les résultats.  
      Le nettoyage est donc une étape <strong>indispensable</strong> pour obtenir une base de données plus cohérente, homogène et exploitable.
    </p>
    
    <h3>🎯 Objectif</h3>
    <p>
      Améliorer la qualité des données textuelles en supprimant les éléments inutiles ou redondants, tout en conservant l’information pertinente pour l’analyse.
    </p>
  
    <h3>⚙️ Étapes de nettoyage</h3>
    <ul>
      <li><strong>Détection automatique de la langue</strong> : identifier la langue de chaque commentaire pour appliquer un nettoyage adapté.</li>
      <li><strong>Conversion en minuscules</strong> : uniformiser le texte afin d’éviter les doublons liés aux majuscules/minuscules.</li>
      <li><strong>Suppression de la ponctuation</strong> : éliminer les caractères spéciaux ou symboles qui n’apportent pas de valeur sémantique.</li>
      <li><strong>Suppression des stopwords</strong> : retirer les mots vides (ex. : « le », « de », « et » en français ou « the », « and », « of » en anglais) en fonction de la langue détectée.</li>
    </ul>
  
  <h3>✅ Résultat attendu</h3>
  <p>
    À l’issue de cette étape, la base de données textuelles est <strong>propre, normalisée et directement exploitable</strong>.  
    Ce processus de prétraitement permet d’améliorer significativement les performances des algorithmes de traitement du langage naturel (NLP) et de limiter les biais causés par le bruit présent dans les données brutes.
  </p>
  
  <div class="example-block">
    <img src="raw_text_example.png" alt="Exemple de texte brut non nettoyé">
    <div class="caption">🔴 Exemple de données brutes avant nettoyage.</div>
  </div>
  
  <div class="example-block">
    <img src="cleaned_text_example.png" alt="Exemple de texte nettoyé">
    <div class="caption">🟢 Exemple de données après nettoyage.</div>
  </div>
</div>


<div id="step3" class="content-section">
  <h2>3️⃣ Prédiction de la note produit</h2>

  <p>
    Cette étape vise à <strong>prédire la note attendue d’un produit</strong> (sur 5 étoiles) à partir de plusieurs sources d’information. 
    La combinaison de données textuelles, numériques, catégorielles et visuelles permet d’obtenir une évaluation fiable de la qualité perçue du produit, 
    ainsi qu’une estimation du <strong>risque de retour</strong>.
  </p>

  <h3>🎯 Objectif</h3>
  <p>
    Déterminer automatiquement la note probable d’un produit et identifier les articles susceptibles d’obtenir une mauvaise évaluation (≤ 2 étoiles).
  </p>

  <h3>📦 Features utilisées</h3>
  <ul>
    <li><strong>Titre du produit (texte)</strong> → vectorisé avec <em>TF-IDF</em> pour extraire les mots-clés pertinents.</li>
    <li><strong>Prix de vente (numérique)</strong> → normalisé et complété en cas de valeurs manquantes.</li>
    <li><strong>ASIN (catégoriel)</strong> → encodé en vecteurs binaires (One-Hot Encoding).</li>
    <li><strong>Image principale (visuel)</strong> → convertie en vecteur de caractéristiques via un réseau de neurones pré-entraîné (<em>ResNet18 tronqué</em>).</li>
  </ul>

  <h3>⚙️ Méthodologie</h3>
  <p>
    Chaque type de donnée est traité avec une méthode adaptée :
  </p>
  <ul>
    <li><em>TF-IDF</em> → pondère les mots selon leur importance relative dans le corpus.</li>
    <li><em>Normalisation</em> → met les valeurs numériques (prix) sur une échelle comparable.</li>
    <li><em>One-Hot Encoding</em> → transforme les identifiants produits en variables exploitables.</li>
    <li><em>Extraction d’images</em> → capture les caractéristiques visuelles (couleurs, textures, formes) dans un vecteur de 512 dimensions.</li>
  </ul>

  <h3>🔗 Combinaison</h3>
  <p>
    Les représentations issues des différentes sources sont <strong>fusionnées en un vecteur unique</strong>, 
    utilisé comme entrée pour le modèle prédictif.  
    Cette approche multi-modale améliore la précision en exploitant simultanément :
  </p>
  <ul>
    <li>le texte (description du produit),</li>
    <li>les données chiffrées (prix),</li>
    <li>les identifiants (ASIN),</li>
    <li>les signaux visuels (image).</li>
  </ul>

  <h3>✅ Résultat attendu</h3>
  <p>
    Le système génère :
  </p>
  <ul>
    <li>Une <strong>note prédite</strong> (<code>rating_pred</code>, entre 1 et 5).</li>
    <li>Une <strong>estimation du risque de retour.</strong></li>
  </ul>

  <!-- Conteneur pour le flowchart en PNG -->
  <div style="text-align:center; margin:20px 0;">
    <img src="flowshart.png" alt="Flowchart" style="max-width:800px; width:100%; height:auto;">
  </div>
</div>





<div id="step4" class="content-section">
  <h2>4️⃣ Optimisation des hyperparamètres du modèle</h2>

  <p>
    Cette étape consiste à <strong>optimiser les performances d’un modèle d’ensemble de type RandomForest</strong> appliqué à la prédiction de la note produit. 
    RandomForest est une méthode basée sur la combinaison de plusieurs arbres de décision, ce qui permet de réduire la variance et d’améliorer la robustesse de la prédiction.
  </p>

  <h3>🎯 Méthodologie</h3>
  <p>
    Les données préparées précédemment (texte TF-IDF, prix normalisé, identifiants produits encodés et vecteurs d’images) sont <strong>concaténées en un vecteur unique</strong> pour servir d’entrée au modèle. 
    Ensuite, nous effectuons une recherche d’hyperparamètres pour identifier la configuration qui minimise l’erreur de prédiction.
  </p>
  <ul>
    <li><strong>n_estimators</strong> : nombre d’arbres dans la forêt.</li>
    <li><strong>max_depth</strong> : profondeur maximale de chaque arbre.</li>
    <li><strong>max_features (TF-IDF)</strong> : nombre maximal de mots-clés pris en compte dans la vectorisation du texte.</li>
  </ul>
  <p>
    Pour chaque combinaison de paramètres, nous calculons la <strong>Root Mean Squared Error (RMSE)</strong> sur le jeu de test afin de déterminer les réglages optimaux.
  </p>

  <h3>📊 Résultats</h3>
  <ul>
    <li><strong>Meilleure RMSE :</strong> 0.4161 avec <code>n_estimators=220</code> et <code>max_depth=7</code></li>
    <li><strong>Meilleur nombre de features TF-IDF :</strong> 260, donnant une RMSE=0.415</li>
  </ul>

  <!-- Images côte à côte -->
  <div class="images-container" style="display:flex; gap:20px; justify-content:center; flex-wrap:wrap; margin:20px 0;">
    <div class="image-box" style="flex:0 1 45%; text-align:center;">
      <img src="RF_hyper.png" alt="Courbe de tuning RandomForest" style="width:100%; height:auto; object-fit:contain;">
      <div class="caption">Variation de la performance selon le nombre d’estimateurs et la profondeur.</div>
    </div>
    <div class="image-box" style="flex:0 1 45%; text-align:center;">
      <img src="RF_hyper_tf_df.png" alt="Optimisation TF-IDF RandomForest" style="width:100%; height:auto; object-fit:contain;">
      <div class="caption">Optimisation conjointe de TF-IDF max_features et des paramètres RandomForest.</div>
    </div>
  </div>

  <h3>✅ Conclusion</h3>
  <p>
    L’utilisation de RandomForest sur les données multi-modales concaténées (texte, numérique, catégoriel et visuel) a permis d’obtenir des prédictions fiables des notes produits. 
    La recherche d’hyperparamètres a montré que <code>n_estimators=220</code>, <code>max_depth=7</code> et <code>max_features=260</code> pour la TF-IDF offrent un bon compromis entre précision et complexité. 
    Cette configuration garantit que le modèle exploite efficacement toutes les caractéristiques extraites tout en restant stable et généralisable sur de nouvelles données.
  </p>
</div>


<div id="step5" class="content-section">
  <h2>5️⃣ Optimisation des hyperparamètres CatBoost</h2>

  <p>
    Cette étape consiste à <strong>optimiser les performances d’un modèle CatBoost</strong> appliqué à la prédiction de la note produit. 
    CatBoost est un modèle de gradient boosting sur arbres, spécialement conçu pour gérer les variables catégorielles et les données hétérogènes tout en étant robuste au surapprentissage.
  </p>

  <h3>🎯 Méthodologie</h3>
  <p>
    Les données préparées précédemment (texte TF-IDF, prix normalisé, identifiants produits encodés et vecteurs d’images) sont <strong>concaténées en un vecteur unique</strong> pour servir d’entrée au modèle. 
    Nous effectuons ensuite une recherche d’hyperparamètres pour identifier la configuration qui minimise l’erreur de prédiction.
  </p>
  <ul>
    <li><strong>iterations</strong> : nombre d’itérations (arbres) dans le boosting.</li>
    <li><strong>depth</strong> : profondeur maximale de chaque arbre.</li>
    <li><strong>learning_rate</strong> : taux d’apprentissage.</li>
    <li><strong>max_features (TF-IDF)</strong> : nombre maximal de mots-clés pris en compte dans la vectorisation du texte.</li>
  </ul>
  <p>
    Pour chaque combinaison de paramètres, nous calculons la <strong>Root Mean Squared Error (RMSE)</strong> sur le jeu de test afin de déterminer les réglages optimaux.
  </p>

  <h3>📊 Résultats</h3>
  <ul>
    <li><strong>Meilleure RMSE :</strong> 0.4138 avec <code>iterations=350</code>, <code>learning_rate=0.3</code> et <code>depth=6</code></li>
    <li><strong>Meilleur nombre de features TF-IDF :</strong> 300 → RMSE=0.3484</li>
  </ul>

  <!-- Images côte à côte -->
  <div class="images-container" style="display:flex; gap:20px; justify-content:center; flex-wrap:wrap; margin:20px 0;">
    <div class="image-box" style="flex:0 1 45%; text-align:center;">
      <img src="cat_hyper.png" alt="Courbe de tuning CatBoost" style="width:100%; height:auto; object-fit:contain;">
      <div class="caption">Exemple d’entraînement CatBoost avec early stopping.</div>
    </div>
    <div class="image-box" style="flex:0 1 45%; text-align:center;">
      <img src="cat_hyper_tf.png" alt="Optimisation TF-IDF CatBoost" style="width:100%; height:auto; object-fit:contain;">
      <div class="caption">Optimisation conjointe des paramètres CatBoost et de TF-IDF max_features.</div>
    </div>
  </div>

  <h3>✅ Conclusion</h3>
  <p>
    L’utilisation de CatBoost sur les données multi-modales concaténées (texte, numérique, catégoriel et visuel) a permis d’obtenir des prédictions précises des notes produits. 
    La recherche d’hyperparamètres a montré que <code>iterations=350</code>, <code>depth=6</code>, <code>learning_rate=0.3</code> et <code>max_features=300</code> pour la TF-IDF offrent un excellent compromis entre précision et complexité. 
    Cette configuration garantit que le modèle exploite efficacement toutes les caractéristiques extraites tout en restant stable et généralisable sur de nouvelles données.
  </p>
</div>


<div id="model-doc" class="content-section">
  <h2>📘 Documentation technique du modèle d’apprentissage</h2>

  <h3>1️⃣ Modèles utilisés</h3>
  <ul>
    <li><strong>RandomForest :</strong> modèle de forêt d’arbres de décision, robuste aux données bruitées et multi-modales. Modèle sauvegardé en <code>.pkl</code>.</li>
    <li><strong>CatBoost :</strong> modèle de gradient boosting sur arbres, performant sur les variables catégorielles et les jeux de données hétérogènes. Modèle sauvegardé en <code>.cbm</code>.</li>
  </ul>

  <h3>2️⃣ Paramètres optimaux</h3>
  <p>
    Chaque modèle est entraîné avec les **meilleurs hyperparamètres** identifiés lors de la phase de tuning :
  </p>
  <ul>
    <li>RandomForest : <code>n_estimators=220</code>, <code>max_depth=7</code>, <code>max_features=260</code> pour TF-IDF.</li>
    <li>CatBoost : <code>iterations=350</code>, <code>depth=6</code>, <code>learning_rate=0.3</code>, <code>max_features=300</code> pour TF-IDF.</li>
  </ul>

  <h3>3️⃣ Données d’entrée</h3>
  <p>
    Le modèle reçoit des vecteurs concaténés issus de différentes sources :
  </p>
  <ul>
    <li>Texte produit vectorisé via TF-IDF.</li>
    <li>Prix et caractéristiques numériques normalisés.</li>
    <li>Identifiants produits encodés (catégoriels).</li>
    <li>Vecteurs d’images extraits via un réseau de type CNN ou vision transformer.</li>
  </ul>

  <h3>4️⃣ Mécanisme de prédiction</h3>
  <p>
    Les modèles chargés génèrent des prédictions sous forme de **probabilités basées sur les notes produits**, permettant ainsi de produire :
  </p>
  <ul>
    <li>Une estimation précise de la note attendue.</li>
    <li>Des scores ou recommandations pour chaque produit.</li>
  </ul>

  <h3>5️⃣ Déploiement en ligne</h3>
  <p>
    Pour l’intégration dans l’application web, nous utilisons **Hugging Face comme serveur Python**. Cela permet de :
  </p>
  <ul>
    <li>Charger les modèles pré-entraînés en mémoire.</li>
    <li>Fournir des prédictions en temps réel pour des requêtes utilisateur.</li>
    <li>Assurer la scalabilité et la robustesse du pipeline en ligne.</li>
  </ul>
</div>




<script>
  function showStep(step) {
    document.querySelectorAll('.content-section').forEach(sec => sec.classList.remove('active'));
    document.querySelectorAll('.step').forEach(b => b.classList.remove('active'));
    document.getElementById('step' + step).classList.add('active');
    document.querySelector('.steps-bar .step:nth-child(' + step + ')').classList.add('active');
  }
</script>

</body>
</html>
