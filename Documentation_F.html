<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Pipeline Multi-modale</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 0; background: #f5f5f5; }
    h1 { text-align: center; padding: 20px; color: #333; }
    
    /* Barre de bulles */
    .steps-bar {
      display: flex;
      justify-content: center;
      align-items: center;
      background: #fff;
      padding: 15px;
      box-shadow: 0 2px 6px rgba(0,0,0,0.1);
      position: sticky;
      top: 0;
      z-index: 1000;
      gap: 20px;
      flex-wrap: wrap;
    }
    .step {
      width: 60px;
      height: 60px;
      border-radius: 50%;
      background: #ddd;
      display: flex;
      align-items: center;
      justify-content: center;
      font-weight: bold;
      cursor: pointer;
      transition: all 0.3s;
    }
    .step.active {
      background: #4CAF50;
      color: #fff;
      transform: scale(1.1);
    }
    .step:hover { background: #66bb6a; color: #fff; }

    /* Sections */
    .content-section {
      display: none;
      background: #fff;
      margin: 20px auto;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 0 6px rgba(0,0,0,0.1);
      width: 90%;
      max-width: 1000px;
      animation: fadeIn 0.5s ease;
    }
    .content-section.active { display: block; }

    /* Images */
    .images { display: flex; justify-content: center; gap: 20px; margin: 20px 0; flex-wrap: wrap; }
    .images img { width: 320px; height: 220px; object-fit: cover; border-radius: 8px; cursor: pointer; box-shadow: 0 0 8px rgba(0,0,0,0.2); }
    .caption { text-align: center; font-style: italic; margin-top: 5px; }

    video { max-width: 100%; border-radius: 8px; box-shadow: 0 0 8px rgba(0,0,0,0.2); }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
  </style>
</head>
<body>

<h1>Pipeline Multi-modale</h1>

<!-- Bulles -->
<div class="steps-bar">
  <div class="step active" onclick="showStep(1)">1</div>
  <div class="step" onclick="showStep(2)">2</div>
  <div class="step" onclick="showStep(3)">3</div>
  <div class="step" onclick="showStep(4)">4</div>
  <div class="step" onclick="showStep(5)">5</div>
  <div class="step" onclick="showStep(6)">6</div>
  <div class="step" onclick="showStep(7)">7</div>
</div>

<!-- Sections -->
<div id="step1" class="content-section active">
  <h2>1️⃣ Data Collection</h2>
  <p>
    L’étape de <strong>collecte des données brutes</strong> consiste à extraire et centraliser toutes les informations nécessaires à partir des pages produits du magasin <em>Ponera</em> sur Amazon.
  </p>
  
  <h3>🎯 Objectif</h3>
  <p>
    Constituer une base de données fiable, normalisée et exploitable qui servira de fondation à l’entraînement et à l’optimisation du modèle d’intelligence artificielle.
  </p>

  <h3>⚙️ Outil utilisé</h3>
  <p>
    L’extension <strong>IMPORTFROMWEB</strong> pour Google Sheets permet d’automatiser la collecte des données produits. 
    Cette automatisation offre :
  </p>
  <ul>
    <li>Un <strong>gain de temps</strong> dans la récupération des données,</li>
    <li>Une <strong>réduction des erreurs humaines</strong> liées à la saisie manuelle,</li>
    <li>Une <strong>mise à jour dynamique</strong> des informations collectées.</li>
  </ul>

  <h3>📦 Données collectées</h3>
  <p>Les caractéristiques extraites incluent :</p>
  <ul>
    <li><strong>ASIN</strong> : identifiant unique du produit sur Amazon,</li>
    <li><strong>Titre du produit</strong>,</li>
    <li><strong>Prix</strong>,</li>
    <li><strong>Note moyenne des clients</strong>,</li>
    <li><strong>Nombre total de commentaires</strong>,</li>
    <li><strong>Contenu des avis clients</strong>.</li>
  </ul>

  <h3>✅ Résultat attendu</h3>
  <p>
    Une base de données organisée dans Google Sheets, rassemblant toutes les informations nécessaires sous un format uniforme, prête à être utilisée pour les analyses et les applications d’IA.
  </p>

  <video controls>
    <source src="data_collection.mp4" type="video/mp4">
    Votre navigateur ne supporte pas la lecture vidéo.
  </video>
</div>

<div id="step2" class="content-section">
    <h2>2️⃣ Nettoyage des textes</h2>
    
    <p>
      Cette étape consiste à <strong>préparer et uniformiser la base de données textuelles</strong> afin de garantir la qualité des informations qui seront utilisées dans les traitements d’analyse et dans l’entraînement du modèle d’intelligence artificielle.  
      Un texte brut contient souvent du bruit (ponctuation, majuscules, mots sans importance, etc.), ce qui peut fausser les résultats.  
      Le nettoyage est donc une étape <strong>indispensable</strong> pour obtenir une base de données plus cohérente, homogène et exploitable.
    </p>
    
    <h3>🎯 Objectif</h3>
    <p>
      Améliorer la qualité des données textuelles en supprimant les éléments inutiles ou redondants, tout en conservant l’information pertinente pour l’analyse.
    </p>
  
    <h3>⚙️ Étapes de nettoyage</h3>
    <ul>
      <li><strong>Détection automatique de la langue</strong> : identifier la langue de chaque commentaire pour appliquer un nettoyage adapté.</li>
      <li><strong>Conversion en minuscules</strong> : uniformiser le texte afin d’éviter les doublons liés aux majuscules/minuscules.</li>
      <li><strong>Suppression de la ponctuation</strong> : éliminer les caractères spéciaux ou symboles qui n’apportent pas de valeur sémantique.</li>
      <li><strong>Suppression des stopwords</strong> : retirer les mots vides (ex. : « le », « de », « et » en français ou « the », « and », « of » en anglais) en fonction de la langue détectée.</li>
    </ul>
  
  <h3>✅ Résultat attendu</h3>
  <p>
    À l’issue de cette étape, la base de données textuelles est <strong>propre, normalisée et directement exploitable</strong>.  
    Ce processus de prétraitement permet d’améliorer significativement les performances des algorithmes de traitement du langage naturel (NLP) et de limiter les biais causés par le bruit présent dans les données brutes.
  </p>
  
  <div class="example-block">
    <img src="raw_text_example.png" alt="Exemple de texte brut non nettoyé">
    <div class="caption">🔴 Exemple de données brutes avant nettoyage.</div>
  </div>
  
  <div class="example-block">
    <img src="cleaned_text_example.png" alt="Exemple de texte nettoyé">
    <div class="caption">🟢 Exemple de données après nettoyage.</div>
  </div>
</div>


<div id="step3" class="content-section">
  <h2>3️⃣ Prédiction de la note produit</h2>

  <p>
    Cette étape vise à <strong>prédire la note attendue d’un produit</strong> (sur 5 étoiles) à partir de plusieurs sources d’information. 
    La combinaison de données textuelles, numériques, catégorielles et visuelles permet d’obtenir une évaluation fiable de la qualité perçue du produit, 
    ainsi qu’une estimation du <strong>risque de retour</strong>.
  </p>

  <h3>🎯 Objectif</h3>
  <p>
    Déterminer automatiquement la note probable d’un produit et identifier les articles susceptibles d’obtenir une mauvaise évaluation (≤ 2 étoiles).
  </p>

  <h3>📦 Features utilisées</h3>
  <ul>
    <li><strong>Titre du produit (texte)</strong> → vectorisé avec <em>TF-IDF</em> pour extraire les mots-clés pertinents.</li>
    <li><strong>Prix de vente (numérique)</strong> → normalisé et complété en cas de valeurs manquantes.</li>
    <li><strong>ASIN (catégoriel)</strong> → encodé en vecteurs binaires (One-Hot Encoding).</li>
    <li><strong>Image principale (visuel)</strong> → convertie en vecteur de caractéristiques via un réseau de neurones pré-entraîné (<em>ResNet18 tronqué</em>).</li>
  </ul>

  <h3>⚙️ Méthodologie</h3>
  <p>
    Chaque type de donnée est traité avec une méthode adaptée :
  </p>
  <ul>
    <li><em>TF-IDF</em> → pondère les mots selon leur importance relative dans le corpus.</li>
    <li><em>Normalisation</em> → met les valeurs numériques (prix) sur une échelle comparable.</li>
    <li><em>One-Hot Encoding</em> → transforme les identifiants produits en variables exploitables.</li>
    <li><em>Extraction d’images</em> → capture les caractéristiques visuelles (couleurs, textures, formes) dans un vecteur de 512 dimensions.</li>
  </ul>

  <h3>🔗 Combinaison</h3>
  <p>
    Les représentations issues des différentes sources sont <strong>fusionnées en un vecteur unique</strong>, 
    utilisé comme entrée pour le modèle prédictif.  
    Cette approche multi-modale améliore la précision en exploitant simultanément :
  </p>
  <ul>
    <li>le texte (description du produit),</li>
    <li>les données chiffrées (prix),</li>
    <li>les identifiants (ASIN),</li>
    <li>les signaux visuels (image).</li>
  </ul>

  <h3>✅ Résultat attendu</h3>
  <p>
    Le système génère :
  </p>
  <ul>
    <li>Une <strong>note prédite</strong> (<code>rating_pred</code>, entre 1 et 5).</li>
    <li>Une <strong>estimation du risque de retour.</strong></li>
  </ul>

  <!-- Conteneur pour le flowchart en PNG -->
  <div style="text-align:center; margin:20px 0;">
    <img src="flowchart.png" alt="Flowchart" style="max-width:800px; width:100%; height:auto;">
  </div>
</div>





<div id="step4" class="content-section">
  <h2>4️⃣ Optimisation des hyperparamètres du modèle</h2>

  <p>
    Cette étape consiste à <strong>optimiser les performances d’un modèle d’ensemble de type RandomForest</strong> appliqué à la prédiction de la note produit. 
    RandomForest est une méthode basée sur la combinaison de plusieurs arbres de décision, ce qui permet de réduire la variance et d’améliorer la robustesse de la prédiction.
  </p>

  <h3>🎯 Méthodologie</h3>
  <p>
    Les données préparées précédemment (texte TF-IDF, prix normalisé, identifiants produits encodés et vecteurs d’images) sont <strong>concaténées en un vecteur unique</strong> pour servir d’entrée au modèle. 
    Ensuite, nous effectuons une recherche d’hyperparamètres pour identifier la configuration qui minimise l’erreur de prédiction.
  </p>
  <ul>
    <li><strong>n_estimators</strong> : nombre d’arbres dans la forêt.</li>
    <li><strong>max_depth</strong> : profondeur maximale de chaque arbre.</li>
    <li><strong>max_features (TF-IDF)</strong> : nombre maximal de mots-clés pris en compte dans la vectorisation du texte.</li>
  </ul>
  <p>
    Pour chaque combinaison de paramètres, nous calculons la <strong>Root Mean Squared Error (RMSE)</strong> sur le jeu de test afin de déterminer les réglages optimaux.
  </p>

  <h3>📊 Résultats</h3>
  <ul>
    <li><strong>Meilleure RMSE :</strong> 0.4161 avec <code>n_estimators=220</code> et <code>max_depth=7</code></li>
    <li><strong>Meilleur nombre de features TF-IDF :</strong> 260, donnant une RMSE=0.415</li>
  </ul>

  <div class="images">
    <div>
      <img src="RF_hyper.png" alt="Courbe de tuning RandomForest">
      <div class="caption">Variation de la performance selon le nombre d’estimateurs et la profondeur.</div>
    </div>
    <div>
      <img src="RF_hyper_tf_df.png" alt="Optimisation TF-IDF RandomForest">
      <div class="caption">Optimisation conjointe de TF-IDF max_features et des paramètres RandomForest.</div>
    </div>
  </div>

  <h3>✅ Conclusion</h3>
  <p>
    L’utilisation de RandomForest sur les données multi-modales concaténées (texte, numérique, catégoriel et visuel) a permis d’obtenir des prédictions fiables des notes produits. 
    La recherche d’hyperparamètres a montré que <code>n_estimators=220</code>, <code>max_depth=7</code> et <code>max_features=260</code> pour la TF-IDF offrent un bon compromis entre précision et complexité. 
    Cette configuration garantit que le modèle exploite efficacement toutes les caractéristiques extraites tout en restant stable et généralisable sur de nouvelles données.
  </p>
</div>

</div>

<div id="step5" class="content-section">
  <h2>5️⃣ Hyperparameter-tuning CatBoost</h2>
  <p>CatBoost est utilisé pour traiter efficacement les données hétérogènes :</p>
  <ul>
    <li>Support natif des données catégorielles (ex. <code>ASIN</code>).</li>
    <li>Gestion automatique des valeurs manquantes.</li>
    <li>Robuste aux déséquilibres de classes.</li>
  </ul>
  <div class="images">
    <div>
      <img src="cat_hyper.png" alt="Entraînement CatBoost">
      <div class="caption">Exemple d’entraînement CatBoost avec early stopping.</div>
    </div>
    <div>
      <img src="cat_hyper_tf.png" alt="Résultats CatBoost">
      <div class="caption">Comparaison des performances : CatBoost vs RandomForest.</div>
    </div>
  </div>
  <ul>
    <li><strong>Best CatBoost parameters</strong> : {iterations=350, learning_rate=0.3, depth=6} → RMSE = 0.4138</li>
    <li><strong>Best max_features</strong> : 300 → RMSE = 0.3484</li>
  </ul>
</div>

<div id="step6" class="content-section">
  <h2>6️⃣ Schéma global du pipeline</h2>
  <p>De la base brute jusqu’au modèle supervisé :</p>
  <img src="pipeline_diagram.png" alt="Schéma pipeline" style="max-width:100%; border-radius:8px;">
</div>

<div id="step7" class="content-section">
  <h2>7️⃣ Avantages</h2>
  <ul>
    <li>Pipeline complet : collecte → nettoyage → features → modèle.</li>
    <li>Multi-modalité : texte, prix, catégorie, image.</li>
    <li>Standardisation multilingue.</li>
  </ul>
</div>

<script>
  function showStep(step) {
    document.querySelectorAll('.content-section').forEach(sec => sec.classList.remove('active'));
    document.querySelectorAll('.step').forEach(b => b.classList.remove('active'));
    document.getElementById('step' + step).classList.add('active');
    document.querySelector('.steps-bar .step:nth-child(' + step + ')').classList.add('active');
  }
</script>

</body>
</html>
